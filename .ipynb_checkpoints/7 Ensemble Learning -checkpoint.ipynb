{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b93fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a11dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data set\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep= ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "955f3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the target data and data\n",
    "\n",
    "x = df.drop(columns=['quality'])\n",
    "y = df['quality']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44c9d44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the descion tree model\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30d7dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the values\n",
    "\n",
    "y_pred = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d9fb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b85dddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mClassification Report of Decision Tree : \n",
      "\u001b[31m               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.24      0.28      0.26        25\n",
      "           5       0.66      0.64      0.65       291\n",
      "           6       0.64      0.63      0.63       432\n",
      "           7       0.61      0.59      0.60       192\n",
      "           8       0.31      0.49      0.38        35\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61       980\n",
      "   macro avg       0.35      0.37      0.36       980\n",
      "weighted avg       0.61      0.61      0.61       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Printing the classification model\n",
    "print(Fore.GREEN +\"Classification Report of Decision Tree : \")\n",
    "print(Fore.RED, classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2e5c989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), bootstrap=False,\n",
       "                  n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the bagging classifier\n",
    "\n",
    "bc =BaggingClassifier(base_estimator= DecisionTreeClassifier(), n_estimators=100,bootstrap=False,  random_state=42)\n",
    "#fit the model\n",
    "bc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cbde357",
   "metadata": {},
   "outputs": [],
   "source": [
    "yb_pred = bc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5612dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mClassification Reportmodel of Bagging Classifier : \n",
      "\u001b[33m              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.25      0.32      0.28        25\n",
      "           5       0.66      0.63      0.64       291\n",
      "           6       0.64      0.64      0.64       432\n",
      "           7       0.61      0.60      0.61       192\n",
      "           8       0.36      0.46      0.41        35\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61       980\n",
      "   macro avg       0.36      0.38      0.37       980\n",
      "weighted avg       0.61      0.61      0.61       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(Fore.BLUE +\"Classification Reportmodel of Bagging Classifier : \")\n",
    "print(Fore.YELLOW + classification_report(y_test, yb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35b929c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m 0.6061224489795919\n",
      "\u001b[32m 0.6112244897959184\n"
     ]
    }
   ],
   "source": [
    "#printing the scores\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(Fore.RED , accuracy_score(y_test, y_pred))\n",
    "print(Fore.GREEN , accuracy_score(y_test, yb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab313f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mR2 Score of Bagging : \n",
      "\u001b[32m 0.19365854445525976\n"
     ]
    }
   ],
   "source": [
    "#printing the r2 scpore \n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(Fore.RED + \"R2 Score of Bagging : \")\n",
    "print(Fore.GREEN, r2_score(y_test, yb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Out of Bag Score for Bagging Classifier\n",
    "\n",
    "bag_obb = BaggingClassifier(base_estimator = DecisiontreeClassifier(), n_estimators = 100, oob_score = True, random_state = 42)\n",
    "bag_obb.fit(x_train, y_train)\n",
    "oob_score = bag_obb.oob_score_\n",
    "print(Out - )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
